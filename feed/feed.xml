<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="pretty-atom-feed.xsl" type="text/xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <title>Aelix&#39;s Blog</title>
  <subtitle>Explore the dark forest with me</subtitle>
  <link href="https://aelix.dev/feed/feed.xml" rel="self" />
  <link href="https://aelix.dev/" />
  <updated>2025-11-03T00:00:00Z</updated>
  <id>https://aelix.dev/</id>
  <author>
    <name>Aelix</name>
  </author>
  <entry>
    <title>Decision Market Arbitrage</title>
    <link href="https://aelix.dev/blog/decision-market-arbitrage/" />
    <updated>2025-11-03T00:00:00Z</updated>
    <id>https://aelix.dev/blog/decision-market-arbitrage/</id>
    <content type="html">&lt;img src=&quot;https://aelix.dev/DMA.png&quot; alt=&quot;Decision Market Arbitrage&quot;&gt;
&lt;p&gt;Ever wondered how to profit from inefficient futarchy markets? Here&#39;s a simple guide to arbitraging decision markets — a mechanism that&#39;s still new enough to have simple alpha.&lt;/p&gt;
&lt;h2 id=&quot;what-is-futarchy&quot;&gt;What is futarchy?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.ethereum.org/2014/08/21/introduction-futarchy&quot;&gt;This post by Vitalik&lt;/a&gt; is my favorite resource and offers a good in-depth analysis of the mechanism (including a quick overview of potential issues). &lt;a href=&quot;https://futarchy.guide/&quot;&gt;futarchy.guide&lt;/a&gt; is a pretty cool visualization for &lt;a href=&quot;https://x.com/MetaDAOProject&quot;&gt;@MetaDAOProject&lt;/a&gt; if you aren&#39;t familiar with the conditional vault/AMM architecture.&lt;/p&gt;
&lt;h2 id=&quot;opportunity-1-when-spot-price-both-pass-and-fail-markets&quot;&gt;Opportunity #1: When spot price &amp;gt; both pass and fail markets&lt;/h2&gt;
&lt;p&gt;For simplicity, let&#39;s say a decision market for a proposal is being run for &lt;a href=&quot;https://x.com/zcombinatorio&quot;&gt;@zcombinatorio&lt;/a&gt; (with $ZC as the base token and $SOL as the quote token). Spot is trading 1.75 $SOL per $ZC and the conditional markets are trading at 1.25 and 0.75.&lt;/p&gt;
&lt;img src=&quot;https://aelix.dev/arb-op-1.jpeg&quot; alt=&quot;Arbitrage Opportunity 1&quot;&gt;
&lt;p&gt;You can:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Split $SOL into $pSOL and $fSOL (conditional tokens)&lt;/li&gt;
&lt;li&gt;Swap these conditional SOL tokens for conditional $ZC tokens in both markets&lt;/li&gt;
&lt;li&gt;Merge your conditional $ZC back into regular $ZC&lt;/li&gt;
&lt;li&gt;Sell the $ZC into $SOL on the spot market for profit&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Through this, you basically buy $ZC in the conditional markets and sell it at a higher price in spot. You can do this until price impact equals the price difference (excluding fees).&lt;/p&gt;
&lt;p&gt;Assuming no slippage, if you entered with 1 SOL, you can swap into 1.33 $fZC (1/0.75) in the fail conditional market and 0.8 $pZC (1/1.25) in the pass conditional market. After you merge your conditional $ZC, you&#39;ll have min{1.33, 0.8} = 0.8 $ZC total. You can then sell this $ZC for 1.4 $SOL (0.8*1.75). So you would have made a risk-free 40%!&lt;/p&gt;
&lt;h2 id=&quot;opportunity-2-when-spot-price-both-pass-and-fail-markets&quot;&gt;Opportunity #2: When spot price &amp;lt; both pass and fail markets&lt;/h2&gt;
&lt;p&gt;The reverse works too - buy spot $ZC, split it, swap for conditional $SOL in both markets, then merge.&lt;/p&gt;
&lt;img src=&quot;https://aelix.dev/arb-op-2.jpeg&quot; alt=&quot;Arbitrage Opportunity 2&quot;&gt;
&lt;h2 id=&quot;the-key-insight&quot;&gt;The Key Insight&lt;/h2&gt;
&lt;p&gt;No arbitrage exists when spot trades between pass and fail prices.&lt;/p&gt;
&lt;p&gt;This is how the mechanism was designed to work - efficient decision markets should always trade the conditional markets between spot.&lt;/p&gt;
&lt;p&gt;Think about it: Why would the current price be lower than BOTH the pass scenario AND the fail scenario? Why should it be higher than both?&lt;/p&gt;
&lt;h2 id=&quot;caveats&quot;&gt;Caveats&lt;/h2&gt;
&lt;p&gt;In the math for the above example, I avoided slippage. In the graphs, the price impact for all trades is pretty similar.&lt;/p&gt;
&lt;p&gt;In reality, the LP for the conditional markets will probably be less than that of spot. In fact, a common method to fund decision markets is to share liquidity between the spot and the conditional markets. This means that the conditional markets will just have a fraction of the LP of the spot pool.&lt;/p&gt;
&lt;p&gt;As such, the price impact for trading the conditional markets will be far greater than for spot, and perceived arbs are most likely smaller in execution.&lt;/p&gt;
&lt;h2 id=&quot;current-implementations&quot;&gt;Current Implementations&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://x.com/_futarchy&quot;&gt;@_futarchy&lt;/a&gt; has their &lt;a href=&quot;https://ksan.notion.site/futarchy-implementation&quot;&gt;&amp;quot;Futarchy Solver&amp;quot;&lt;/a&gt; on Ethereum, and &lt;a href=&quot;https://x.com/MetaDAOProject&quot;&gt;@MetaDAOProject&lt;/a&gt; recently released &lt;a href=&quot;https://github.com/metaDAOproject/programs/blob/develop/programs/futarchy/src/state/futarchy_amm.rs&quot;&gt;&amp;quot;Futarchy AMM&amp;quot;&lt;/a&gt; on Solana. Both arbitrage automatically per-swap.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://x.com/percentmarkets&quot;&gt;@percentmarkets&lt;/a&gt; hasn&#39;t implemented this yet, so manual arb opportunities still exist.&lt;/p&gt;
&lt;p&gt;See you in the dark forest.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>An Ideal World Approximator</title>
    <link href="https://aelix.dev/blog/an-ideal-world-approximator/" />
    <updated>2024-10-19T00:00:00Z</updated>
    <id>https://aelix.dev/blog/an-ideal-world-approximator/</id>
    <content type="html">&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://aelix.dev/blog/an-ideal-world-approximator/qxM3sjB71c-960.avif 960w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://aelix.dev/blog/an-ideal-world-approximator/qxM3sjB71c-960.webp 960w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://aelix.dev/blog/an-ideal-world-approximator/qxM3sjB71c-960.jpeg&quot; alt=&quot;Newton by William Blake&quot; width=&quot;960&quot; height=&quot;738&quot;&gt;&lt;/picture&gt;
&lt;em&gt;Newton (1795-1805) by William Blake - The rational measurer attempting to understand the universe&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is a reflection of myself as an agent and what control I have to better my decision making. It&#39;s a little reductionist, but I think it gets a lot of good points across.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;From first principles, a rational agent (you) is a being with information intake, an ability to rationally process that information, and the capability to make/execute decisions based on that processing.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;processing&quot;&gt;Processing&lt;/h2&gt;
&lt;p&gt;Understanding and analyzing the mechanisms of how we process information seems non-trivial, so a lot of it is probably best left to trust. Ideally, you are a perfectly rational actor capable of making the best possible decision given any input. At best, you can hope that you can rationally compare two decisions.&lt;/p&gt;
&lt;p&gt;Interestingly, tied to your ability to process information is some approximation, or model, of the world. There is the way the world actually is, and the way you perceive it. As a purely rational agent, if your approximation of the world matched reality, I suspect that you would be perfectly rational. If you knew everything, would you make any poor decisions?&lt;/p&gt;
&lt;p&gt;Your approximation of the world also appears to change based on the information you are given. If you get pinched and it hurts, you&#39;ll think that pinching is a thing that hurts.&lt;/p&gt;
&lt;p&gt;Additionally, at least for me, this approximation comes to me as an ideal. In my day-to-day life, I don&#39;t think twice about whether what I know is inductive, or how misaligned it is from reality: I treat my approximation as truth. I think that is the way the world actually is, until I&#39;m proved otherwise, and that approximation is forced to update.&lt;/p&gt;
&lt;p&gt;That being said, I&#39;m not quite sure how to become more rational, but you can change your model of the world by feeding yourself new information. This is a pivotal take. We are beings of approximations that think in ideals. That means our perception of the world is based on a relatively small set of inputs, yet we make decisions on it as if we knew what the world is actually like.&lt;/p&gt;
&lt;p&gt;But what about decisions where you know you aren&#39;t certain about the result? If you&#39;ve ever had to face a really tough decision, you might have thought along the lines of &amp;quot;well, if I did x then y would happen ... or if I did z then c or maybe d …&amp;quot;. From my internal observation, this seems to be you using diverging approximations that occur after you&#39;ve recognized you haven&#39;t gathered enough information. Notably, you&#39;re still thinking in terms of ideals (hypothetical world-views), created from previous information intake, and still making predictions about the world based on them.&lt;/p&gt;
&lt;p&gt;In short, it&#39;s probably pretty hard to make good decisions if your approximation of the world is shit.&lt;/p&gt;
&lt;h2 id=&quot;information-intake-and-decisions&quot;&gt;Information Intake &amp;amp; Decisions&lt;/h2&gt;
&lt;p&gt;Hopefully, you are able-minded so you can trust yourself to make rational decisions and able-bodied enough to execute on them. Indeed, a life without either of these would be difficult — so remember to be grateful!&lt;/p&gt;
&lt;p&gt;If you can&#39;t execute on some decision, is that really a good decision? What can you do to be able to execute on it in the future?&lt;/p&gt;
&lt;p&gt;As mentioned before, a better approximation of the world probably leads to a better choice amongst decisions, and that approximation hinges on the information you absorb. &amp;quot;Garbage in, garbage out&amp;quot;.&lt;/p&gt;
&lt;p&gt;You can&#39;t absorb everything, so be highly selective with what you intake.&lt;/p&gt;
&lt;p&gt;This also means the ability to recognize information as garbage is really important!&lt;/p&gt;
&lt;p&gt;If you cater your information intake, you can sculpt your world-view. You can force delusions. Careful with this. Don&#39;t get one-shotted.&lt;/p&gt;
&lt;h2 id=&quot;feedback-loops-and-batching&quot;&gt;Feedback Loops &amp;amp; Batching&lt;/h2&gt;
&lt;p&gt;Unfortunately, since you can&#39;t take in everything, your world-view is probably going to be far off from reality. The only way to correct this is to test your predictions against the world via decisions. Armchair thinkers can convince themselves of anything. This is the danger of pure theory and rationalism. Unless you have contact with reality, your thinking has no friction to propel itself forward.&lt;/p&gt;
&lt;p&gt;This is the purpose of feedback loops. Take in information, decide what to do, and then use the outcome as input. If you predict that pinching doesn&#39;t hurt, and you pinch yourself, and it hurts, then you have learned something new about the world. Your world-view approximation is closer to reality.&lt;/p&gt;
&lt;p&gt;The more you probe the world via decisions, the more chances you have to update your approximation and make better decisions. Since the world is impossibly detailed (?), you&#39;ll want to probe as much as possible. This also means that your choice of feedback loops is incredibly important. If they are too long, then you&#39;re iterating too slowly. Time is extremely costly. If your feedback loop has vague outcomes, then your learnings will be muddied. Of course, just do the best with whatever situation you are in.&lt;/p&gt;
&lt;p&gt;If you have no choice but to run feedback loops that take a long time, try batching. That is, if you can, run multiple experiments at once (batch them). You&#39;ll move that much faster.&lt;/p&gt;
&lt;p&gt;Also consider risk per decision in the feedback loop. If the worst-case outcome for running the loop is high, then it&#39;s less valuable. Information at what cost? If the risk is low, then that is greater incentive to probe the world. What do you have to lose?&lt;/p&gt;
&lt;h2 id=&quot;insanity&quot;&gt;Insanity&lt;/h2&gt;
&lt;p&gt;Einstein said &amp;quot;Insanity is doing the same thing over and over and expecting different results&amp;quot;. I&#39;m not sure how accurate that definition actually is, but from our perspective here, this is worth pondering. Your approximate worldview will always be inaccurate. Why run the same experiment over and over? How are you supposed to improve if you keep feeding yourself the same information? How many times do you need to burn yourself on the stove before you&#39;re convinced it will burn you?&lt;/p&gt;
&lt;p&gt;Of course, the world is complicated. Retrying the same thing often yields different results. But if it doesn&#39;t, then don&#39;t keep banging your head against a wall.&lt;/p&gt;
&lt;p&gt;This highlights the importance of using learnings to update your world-view. Hopefully, the outcome of your first experiment will have taught you enough to try something else. You also have the ability to decide without processing (at the conscious level). You can just make decisions. But then you are most likely not acting to your greatest ability. Our raw decision making is emotional and based on instinct. Worst case, it&#39;s completely random. If you know something about the world, you should probably use that knowledge in your probes.&lt;/p&gt;
&lt;p&gt;Compare your approximation of the world to trying to solve a maze. Would you keep going down the same corridor if you know it&#39;s a dead-end? Would you make random turns even if you have explored some sections?&lt;/p&gt;
&lt;h2 id=&quot;an-ideal-world-approximator&quot;&gt;An Ideal World Approximator&lt;/h2&gt;
&lt;p&gt;What does an ideal world approximator look like? It is a seemingly chaotic, yet extremely rational, agent. Someone whose actions appear unpredictable, yet they are calculated and precisely designed to maximally extract information about the world. All information intake is refined and processed in full. Only interacting with the most effective feedback loops.&lt;/p&gt;
&lt;p&gt;This is an agent that is always probing the world in new ways, but not randomly. All past decisions have informed the next.&lt;/p&gt;
&lt;p&gt;Unattainable, but perhaps you could approximate to be an ideal world approximator!&lt;/p&gt;
&lt;h2 id=&quot;incompleteness-rejecting-perfectionism-and-meta-approximation&quot;&gt;Incompleteness, Rejecting Perfectionism, and Meta-approximation&lt;/h2&gt;
&lt;p&gt;What could you do now to be a better approximator?&lt;/p&gt;
&lt;p&gt;The first hurdle is coming to terms with incompleteness and rejecting perfectionism. That book that got boring? Put it down! Only interested in one section of a book? Read only that one! Developing a new project and the build time is too long? Unless you&#39;ve tested the idea previously, pivot or ship it incomplete! You should only work on the highest ROI tasks. Only intake the highest ROI content. If it is no longer high ROI, pivot unless absolutely necessary. This allows you to approximate new, more effective, feedback loops and refine your information feeds.&lt;/p&gt;
&lt;p&gt;Unless you&#39;re being forced to do something, any expectation is set by you on yourself. It is fictitious. These are barriers that you placed to better yourself, but at some point you have to take off the training wheels.&lt;/p&gt;
&lt;p&gt;Being a perfectionist takes time. You don&#39;t have much of that.&lt;/p&gt;
&lt;p&gt;To better interpret and absorb the outcomes of experiments, take time to reflect on them. This includes analyzing feedback loops and information sources.&lt;/p&gt;
&lt;p&gt;To analyze quality of feedback loops, set reasonable goals for what you seek to achieve with each experiment. It&#39;ll also help with reflection.&lt;/p&gt;
&lt;p&gt;To kickstart better information feeds, reduce time with garbage and create new sources/reflections for the values you seek to improve. Mindfulness meditation also cranks up awareness and allows you to catch garbage as it enters your flow.&lt;/p&gt;
&lt;p&gt;No need to do everything all at once. Plant the seed and water it daily. Iteration takes time. World approximation takes forever :)&lt;/p&gt;
</content>
  </entry>
</feed>